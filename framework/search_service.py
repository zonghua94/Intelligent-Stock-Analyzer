import logging
import random
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from itertools import cycle
import requests
from newspaper import Article, Config

from searcher import (
    BaseSearchProvider,
    SearchResult,
    SearchResponse,
    BochaSearchProvider,
    BraveSearchProvider,
    SerpAPISearchProvider,
    TavilySearchProvider,
)
from utils.logger import Logger

logger = Logger(__name__)


class SearchService:
    """
    æœç´¢æœåŠ¡
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å¤šä¸ªæœç´¢å¼•æ“
    2. è‡ªåŠ¨æ•…éšœè½¬ç§»
    3. ç»“æœèšåˆå’Œæ ¼å¼åŒ–
    4. æ•°æ®æºå¤±è´¥æ—¶çš„å¢å¼ºæœç´¢ï¼ˆè‚¡ä»·ã€èµ°åŠ¿ç­‰ï¼‰
    5. æ¸¯è‚¡/ç¾è‚¡è‡ªåŠ¨ä½¿ç”¨è‹±æ–‡æœç´¢å…³é”®è¯
    """
    
    # å¢å¼ºæœç´¢å…³é”®è¯æ¨¡æ¿ï¼ˆAè‚¡ ä¸­æ–‡ï¼‰
    ENHANCED_SEARCH_KEYWORDS = [
        "{name} è‚¡ç¥¨ ä»Šæ—¥ è‚¡ä»·",
        "{name} {code} æœ€æ–° è¡Œæƒ… èµ°åŠ¿",
        "{name} è‚¡ç¥¨ åˆ†æ èµ°åŠ¿å›¾",
        "{name} Kçº¿ æŠ€æœ¯åˆ†æ",
        "{name} {code} æ¶¨è·Œ æˆäº¤é‡",
    ]

    # å¢å¼ºæœç´¢å…³é”®è¯æ¨¡æ¿ï¼ˆæ¸¯è‚¡/ç¾è‚¡ è‹±æ–‡ï¼‰
    ENHANCED_SEARCH_KEYWORDS_EN = [
        "{name} stock price today",
        "{name} {code} latest quote trend",
        "{name} stock analysis chart",
        "{name} technical analysis",
        "{name} {code} performance volume",
    ]
    
    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        brave_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
    ):
        """
        åˆå§‹åŒ–æœç´¢æœåŠ¡

        Args:
            bocha_keys: åšæŸ¥æœç´¢ API Key åˆ—è¡¨
            tavily_keys: Tavily API Key åˆ—è¡¨
            brave_keys: Brave Search API Key åˆ—è¡¨
            serpapi_keys: SerpAPI Key åˆ—è¡¨
        """
        self._providers: List[BaseSearchProvider] = []

        # åˆå§‹åŒ–æœç´¢å¼•æ“ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        # 1. Bocha ä¼˜å…ˆï¼ˆä¸­æ–‡æœç´¢ä¼˜åŒ–ï¼ŒAIæ‘˜è¦ï¼‰
        if bocha_keys:
            self._providers.append(BochaSearchProvider(bocha_keys))
            logger.info(f"å·²é…ç½® Bocha æœç´¢ï¼Œå…± {len(bocha_keys)} ä¸ª API Key")

        # 2. Tavilyï¼ˆå…è´¹é¢åº¦æ›´å¤šï¼Œæ¯æœˆ 1000 æ¬¡ï¼‰
        if tavily_keys:
            self._providers.append(TavilySearchProvider(tavily_keys))
            logger.info(f"å·²é…ç½® Tavily æœç´¢ï¼Œå…± {len(tavily_keys)} ä¸ª API Key")

        # 3. Brave Searchï¼ˆéšç§ä¼˜å…ˆï¼Œå…¨çƒè¦†ç›–ï¼‰
        if brave_keys:
            self._providers.append(BraveSearchProvider(brave_keys))
            logger.info(f"å·²é…ç½® Brave æœç´¢ï¼Œå…± {len(brave_keys)} ä¸ª API Key")

        # 4. SerpAPI ä½œä¸ºå¤‡é€‰ï¼ˆæ¯æœˆ 100 æ¬¡ï¼‰
        if serpapi_keys:
            self._providers.append(SerpAPISearchProvider(serpapi_keys))
            logger.info(f"å·²é…ç½® SerpAPI æœç´¢ï¼Œå…± {len(serpapi_keys)} ä¸ª API Key")
        
        if not self._providers:
            logger.warning("æœªé…ç½®ä»»ä½•æœç´¢å¼•æ“ API Keyï¼Œæ–°é—»æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")

        # In-memory search result cache: {cache_key: (timestamp, SearchResponse)}
        self._cache: Dict[str, Tuple[float, 'SearchResponse']] = {}
        # Default cache TTL in seconds (10 minutes)
        self._cache_ttl: int = 600
    
    @staticmethod
    def _is_foreign_stock(stock_code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ¸¯è‚¡æˆ–ç¾è‚¡"""
        import re
        code = stock_code.strip()
        # ç¾è‚¡ï¼š1-5ä¸ªå¤§å†™å­—æ¯ï¼Œå¯èƒ½åŒ…å«ç‚¹ï¼ˆå¦‚ BRK.Bï¼‰
        if re.match(r'^[A-Za-z]{1,5}(\.[A-Za-z])?$', code):
            return True
        # æ¸¯è‚¡ï¼šå¸¦ hk å‰ç¼€æˆ– 5ä½çº¯æ•°å­—
        lower = code.lower()
        if lower.startswith('hk'):
            return True
        if code.isdigit() and len(code) == 5:
            return True
        return False

    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æœç´¢å¼•æ“"""
        return any(p.is_available for p in self._providers)

    def _cache_key(self, query: str, max_results: int, days: int) -> str:
        """Build a cache key from query parameters."""
        return f"{query}|{max_results}|{days}"

    def _get_cached(self, key: str) -> Optional['SearchResponse']:
        """Return cached SearchResponse if still valid, else None."""
        entry = self._cache.get(key)
        if entry is None:
            return None
        ts, response = entry
        if time.time() - ts > self._cache_ttl:
            del self._cache[key]
            return None
        logger.debug(f"Search cache hit: {key[:60]}...")
        return response

    def _put_cache(self, key: str, response: 'SearchResponse') -> None:
        """Store a successful SearchResponse in cache."""
        # Hard cap: evict oldest entries when cache exceeds limit
        _MAX_CACHE_SIZE = 500
        if len(self._cache) >= _MAX_CACHE_SIZE:
            now = time.time()
            # First pass: remove expired entries
            expired = [k for k, (ts, _) in self._cache.items() if now - ts > self._cache_ttl]
            for k in expired:
                del self._cache[k]
            # Second pass: if still over limit, evict oldest entries (FIFO)
            if len(self._cache) >= _MAX_CACHE_SIZE:
                excess = len(self._cache) - _MAX_CACHE_SIZE + 1
                oldest = sorted(self._cache.keys(), key=lambda k: self._cache[k][0])[:excess]
                for k in oldest:
                    del self._cache[k]
        self._cache[key] = (time.time(), response)
    
    def search_stock_news(
        self,
        stock_code: str,
        stock_name: str,
        max_results: int = 5,
        focus_keywords: Optional[List[str]] = None
    ) -> SearchResponse:
        """
        æœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            focus_keywords: é‡ç‚¹å…³æ³¨çš„å…³é”®è¯åˆ—è¡¨
            
        Returns:
            SearchResponse å¯¹è±¡
        """
        # æ™ºèƒ½ç¡®å®šæœç´¢æ—¶é—´èŒƒå›´
        # ç­–ç•¥ï¼š
        # 1. å‘¨äºŒè‡³å‘¨äº”ï¼šæœç´¢è¿‘1å¤©ï¼ˆ24å°æ—¶ï¼‰
        # 2. å‘¨å…­ã€å‘¨æ—¥ï¼šæœç´¢è¿‘2-3å¤©ï¼ˆè¦†ç›–å‘¨æœ«ï¼‰
        # 3. å‘¨ä¸€ï¼šæœç´¢è¿‘3å¤©ï¼ˆè¦†ç›–å‘¨æœ«ï¼‰
        today_weekday = datetime.now().weekday()
        if today_weekday == 0: # å‘¨ä¸€
            search_days = 3
        elif today_weekday >= 5: # å‘¨å…­(5)ã€å‘¨æ—¥(6)
            search_days = 2
        else: # å‘¨äºŒ(1) - å‘¨äº”(4)
            search_days = 1

        # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆä¼˜åŒ–æœç´¢æ•ˆæœï¼‰
        is_foreign = self._is_foreign_stock(stock_code)
        if focus_keywords:
            # å¦‚æœæä¾›äº†å…³é”®è¯ï¼Œç›´æ¥ä½¿ç”¨å…³é”®è¯ä½œä¸ºæŸ¥è¯¢
            query = " ".join(focus_keywords)
        elif is_foreign:
            # æ¸¯è‚¡/ç¾è‚¡ä½¿ç”¨è‹±æ–‡æœç´¢å…³é”®è¯
            query = f"{stock_name} {stock_code} stock latest news"
        else:
            # é»˜è®¤ä¸»æŸ¥è¯¢ï¼šè‚¡ç¥¨åç§° + æ ¸å¿ƒå…³é”®è¯
            query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"

        logger.info(f"æœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}({stock_code}), query='{query}', æ—¶é—´èŒƒå›´: è¿‘{search_days}å¤©")

        # Check cache first
        cache_key = self._cache_key(query, max_results, search_days)
        cached = self._get_cached(cache_key)
        if cached is not None:
            logger.info(f"ä½¿ç”¨ç¼“å­˜æœç´¢ç»“æœ: {stock_name}({stock_code})")
            return cached

        # ä¾æ¬¡å°è¯•å„ä¸ªæœç´¢å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results, days=search_days)
            
            if response.success and response.results:
                logger.info(f"ä½¿ç”¨ {provider.name} æœç´¢æˆåŠŸ")
                self._put_cache(cache_key, response)
                return response
            else:
                logger.warning(f"{provider.name} æœç´¢å¤±è´¥: {response.error_message}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¼•æ“")
        
        # æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="æ‰€æœ‰æœç´¢å¼•æ“éƒ½ä¸å¯ç”¨æˆ–æœç´¢å¤±è´¥"
        )
    
    def search_stock_events(
        self,
        stock_code: str,
        stock_name: str,
        event_types: Optional[List[str]] = None
    ) -> SearchResponse:
        """
        æœç´¢è‚¡ç¥¨ç‰¹å®šäº‹ä»¶ï¼ˆå¹´æŠ¥é¢„å‘Šã€å‡æŒç­‰ï¼‰
        
        ä¸“é—¨é’ˆå¯¹äº¤æ˜“å†³ç­–ç›¸å…³çš„é‡è¦äº‹ä»¶è¿›è¡Œæœç´¢
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            event_types: äº‹ä»¶ç±»å‹åˆ—è¡¨
            
        Returns:
            SearchResponse å¯¹è±¡
        """
        if event_types is None:
            if self._is_foreign_stock(stock_code):
                event_types = ["earnings report", "insider selling", "quarterly results"]
            else:
                event_types = ["å¹´æŠ¥é¢„å‘Š", "å‡æŒå…¬å‘Š", "ä¸šç»©å¿«æŠ¥"]
        
        # æ„å»ºé’ˆå¯¹æ€§æŸ¥è¯¢
        event_query = " OR ".join(event_types)
        query = f"{stock_name} ({event_query})"
        
        logger.info(f"æœç´¢è‚¡ç¥¨äº‹ä»¶: {stock_name}({stock_code}) - {event_types}")
        
        # ä¾æ¬¡å°è¯•å„ä¸ªæœç´¢å¼•æ“
        for provider in self._providers:
            if not provider.is_available:
                continue
            
            response = provider.search(query, max_results=5)
            
            if response.success:
                return response
        
        return SearchResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="äº‹ä»¶æœç´¢å¤±è´¥"
        )
    
    def search_comprehensive_intel(
        self,
        stock_code: str,
        stock_name: str,
        max_searches: int = 3
    ) -> Dict[str, SearchResponse]:
        """
        å¤šç»´åº¦æƒ…æŠ¥æœç´¢ï¼ˆåŒæ—¶ä½¿ç”¨å¤šä¸ªå¼•æ“ã€å¤šä¸ªç»´åº¦ï¼‰
        
        æœç´¢ç»´åº¦ï¼š
        1. æœ€æ–°æ¶ˆæ¯ - è¿‘æœŸæ–°é—»åŠ¨æ€
        2. é£é™©æ’æŸ¥ - å‡æŒã€å¤„ç½šã€åˆ©ç©º
        3. ä¸šç»©é¢„æœŸ - å¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_searches: æœ€å¤§æœç´¢æ¬¡æ•°
            
        Returns:
            {ç»´åº¦åç§°: SearchResponse} å­—å…¸
        """
        results = {}
        search_count = 0
        
        # æ ¹æ®è‚¡ç¥¨ç±»å‹é€‰æ‹©æœç´¢å…³é”®è¯è¯­è¨€
        is_foreign = self._is_foreign_stock(stock_code)

        # å®šä¹‰æœç´¢ç»´åº¦
        if is_foreign:
            search_dimensions = [
                {
                    'name': 'latest_news',
                    'query': f"{stock_name} {stock_code} latest news events",
                    'desc': 'æœ€æ–°æ¶ˆæ¯'
                },
                {
                    'name': 'market_analysis',
                    'query': f"{stock_name} analyst rating target price report",
                    'desc': 'æœºæ„åˆ†æ'
                },
                {
                    'name': 'risk_check',
                    'query': f"{stock_name} risk insider selling lawsuit litigation",
                    'desc': 'é£é™©æ’æŸ¥'
                },
                {
                    'name': 'earnings',
                    'query': f"{stock_name} earnings revenue profit growth forecast",
                    'desc': 'ä¸šç»©é¢„æœŸ'
                },
                {
                    'name': 'industry',
                    'query': f"{stock_name} industry competitors market share outlook",
                    'desc': 'è¡Œä¸šåˆ†æ'
                },
            ]
        else:
            search_dimensions = [
                {
                    'name': 'latest_news',
                    'query': f"{stock_name} {stock_code} æœ€æ–° æ–°é—» é‡å¤§ äº‹ä»¶",
                    'desc': 'æœ€æ–°æ¶ˆæ¯'
                },
                {
                    'name': 'market_analysis',
                    'query': f"{stock_name} ç ”æŠ¥ ç›®æ ‡ä»· è¯„çº§ æ·±åº¦åˆ†æ",
                    'desc': 'æœºæ„åˆ†æ'
                },
                {
                    'name': 'risk_check',
                    'query': f"{stock_name} å‡æŒ å¤„ç½š è¿è§„ è¯‰è®¼ åˆ©ç©º é£é™©",
                    'desc': 'é£é™©æ’æŸ¥'
                },
                {
                    'name': 'earnings',
                    'query': f"{stock_name} ä¸šç»©é¢„å‘Š è´¢æŠ¥ è¥æ”¶ å‡€åˆ©æ¶¦ åŒæ¯”å¢é•¿",
                    'desc': 'ä¸šç»©é¢„æœŸ'
                },
                {
                    'name': 'industry',
                    'query': f"{stock_name} æ‰€åœ¨è¡Œä¸š ç«äº‰å¯¹æ‰‹ å¸‚åœºä»½é¢ è¡Œä¸šå‰æ™¯",
                    'desc': 'è¡Œä¸šåˆ†æ'
                },
            ]
        
        logger.info(f"å¼€å§‹å¤šç»´åº¦æƒ…æŠ¥æœç´¢: {stock_name}({stock_code})")
        
        # è½®æµä½¿ç”¨ä¸åŒçš„æœç´¢å¼•æ“
        provider_index = 0
        
        for dim in search_dimensions:
            if search_count >= max_searches:
                break
            
            # é€‰æ‹©æœç´¢å¼•æ“ï¼ˆè½®æµä½¿ç”¨ï¼‰
            available_providers = [p for p in self._providers if p.is_available]
            if not available_providers:
                break
            
            provider = available_providers[provider_index % len(available_providers)]
            provider_index += 1
            
            logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: ä½¿ç”¨ {provider.name}")
            
            response = provider.search(dim['query'], max_results=3)
            results[dim['name']] = response
            search_count += 1
            
            if response.success:
                logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: è·å– {len(response.results)} æ¡ç»“æœ")
            else:
                logger.warning(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: æœç´¢å¤±è´¥ - {response.error_message}")
            
            # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)
        
        return results
    
    def format_intel_report(self, intel_results: Dict[str, SearchResponse], stock_name: str) -> str:
        """
        æ ¼å¼åŒ–æƒ…æŠ¥æœç´¢ç»“æœä¸ºæŠ¥å‘Š
        
        Args:
            intel_results: å¤šç»´åº¦æœç´¢ç»“æœ
            stock_name: è‚¡ç¥¨åç§°
            
        Returns:
            æ ¼å¼åŒ–çš„æƒ…æŠ¥æŠ¥å‘Šæ–‡æœ¬
        """
        lines = [f"ã€{stock_name} æƒ…æŠ¥æœç´¢ç»“æœã€‘"]
        
        # ç»´åº¦å±•ç¤ºé¡ºåº
        display_order = ['latest_news', 'market_analysis', 'risk_check', 'earnings', 'industry']
        
        for dim_name in display_order:
            if dim_name not in intel_results:
                continue
                
            resp = intel_results[dim_name]
            
            # è·å–ç»´åº¦æè¿°
            dim_desc = dim_name
            if dim_name == 'latest_news': dim_desc = 'ğŸ“° æœ€æ–°æ¶ˆæ¯'
            elif dim_name == 'market_analysis': dim_desc = 'ğŸ“ˆ æœºæ„åˆ†æ'
            elif dim_name == 'risk_check': dim_desc = 'âš ï¸ é£é™©æ’æŸ¥'
            elif dim_name == 'earnings': dim_desc = 'ğŸ“Š ä¸šç»©é¢„æœŸ'
            elif dim_name == 'industry': dim_desc = 'ğŸ­ è¡Œä¸šåˆ†æ'
            
            lines.append(f"\n{dim_desc} (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                # å¢åŠ æ˜¾ç¤ºæ¡æ•°
                for i, r in enumerate(resp.results[:4], 1):
                    date_str = f" [{r.published_date}]" if r.published_date else ""
                    lines.append(f"  {i}. {r.title}{date_str}")
                    # å¦‚æœæ‘˜è¦å¤ªçŸ­ï¼Œå¯èƒ½ä¿¡æ¯é‡ä¸è¶³
                    snippet = r.snippet[:150] if len(r.snippet) > 20 else r.snippet
                    lines.append(f"     {snippet}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
        
        return "\n".join(lines)
    
    def batch_search(
        self,
        stocks: List[Dict[str, str]],
        max_results_per_stock: int = 3,
        delay_between: float = 1.0
    ) -> Dict[str, SearchResponse]:
        """
        Batch search news for multiple stocks.
        
        Args:
            stocks: List of stocks
            max_results_per_stock: Max results per stock
            delay_between: Delay between searches (seconds)
            
        Returns:
            Dict of results
        """
        results = {}
        
        for i, stock in enumerate(stocks):
            if i > 0:
                time.sleep(delay_between)
            
            code = stock.get('code', '')
            name = stock.get('name', '')
            
            response = self.search_stock_news(code, name, max_results_per_stock)
            results[code] = response
        
        return results

    def search_stock_price_fallback(
        self,
        stock_code: str,
        stock_name: str,
        max_attempts: int = 3,
        max_results: int = 5
    ) -> SearchResponse:
        """
        Enhance search when data sources fail.
        
        When all data sources (efinance, akshare, tushare, baostock, etc.) fail to get
        stock data, use search engines to find stock trends and price info as supplemental data for AI analysis.
        
        Strategy:
        1. Search using multiple keyword templates
        2. Try all available search engines for each keyword
        3. Aggregate and deduplicate results
        
        Args:
            stock_code: Stock Code
            stock_name: Stock Name
            max_attempts: Max search attempts (using different keywords)
            max_results: Max results to return
            
        Returns:
            SearchResponse object with aggregated results
        """

        if not self.is_available:
            return SearchResponse(
                query=f"{stock_name} è‚¡ä»·èµ°åŠ¿",
                results=[],
                provider="None",
                success=False,
                error_message="æœªé…ç½®æœç´¢å¼•æ“ API Key"
            )
        
        logger.info(f"[å¢å¼ºæœç´¢] æ•°æ®æºå¤±è´¥ï¼Œå¯åŠ¨å¢å¼ºæœç´¢: {stock_name}({stock_code})")
        
        all_results = []
        seen_urls = set()
        successful_providers = []
        
        # ä½¿ç”¨å¤šä¸ªå…³é”®è¯æ¨¡æ¿æœç´¢
        is_foreign = self._is_foreign_stock(stock_code)
        keywords = self.ENHANCED_SEARCH_KEYWORDS_EN if is_foreign else self.ENHANCED_SEARCH_KEYWORDS
        for i, keyword_template in enumerate(keywords[:max_attempts]):
            query = keyword_template.format(name=stock_name, code=stock_code)
            
            logger.info(f"[å¢å¼ºæœç´¢] ç¬¬ {i+1}/{max_attempts} æ¬¡æœç´¢: {query}")
            
            # ä¾æ¬¡å°è¯•å„ä¸ªæœç´¢å¼•æ“
            for provider in self._providers:
                if not provider.is_available:
                    continue
                
                try:
                    response = provider.search(query, max_results=3)
                    
                    if response.success and response.results:
                        # å»é‡å¹¶æ·»åŠ ç»“æœ
                        for result in response.results:
                            if result.url not in seen_urls:
                                seen_urls.add(result.url)
                                all_results.append(result)
                                
                        if provider.name not in successful_providers:
                            successful_providers.append(provider.name)
                        
                        logger.info(f"[å¢å¼ºæœç´¢] {provider.name} è¿”å› {len(response.results)} æ¡ç»“æœ")
                        break  # æˆåŠŸåè·³åˆ°ä¸‹ä¸€ä¸ªå…³é”®è¯
                    else:
                        logger.debug(f"[å¢å¼ºæœç´¢] {provider.name} æ— ç»“æœæˆ–å¤±è´¥")
                        
                except Exception as e:
                    logger.warning(f"[å¢å¼ºæœç´¢] {provider.name} æœç´¢å¼‚å¸¸: {e}")
                    continue
            
            # çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            if i < max_attempts - 1:
                time.sleep(0.5)
        
        # æ±‡æ€»ç»“æœ
        if all_results:
            # æˆªå–å‰ max_results æ¡
            final_results = all_results[:max_results]
            provider_str = ", ".join(successful_providers) if successful_providers else "None"
            
            logger.info(f"[å¢å¼ºæœç´¢] å®Œæˆï¼Œå…±è·å– {len(final_results)} æ¡ç»“æœï¼ˆæ¥æº: {provider_str}ï¼‰")
            
            return SearchResponse(
                query=f"{stock_name}({stock_code}) è‚¡ä»·èµ°åŠ¿",
                results=final_results,
                provider=provider_str,
                success=True,
            )
        else:
            logger.warning(f"[å¢å¼ºæœç´¢] æ‰€æœ‰æœç´¢å‡æœªè¿”å›ç»“æœ")
            return SearchResponse(
                query=f"{stock_name}({stock_code}) è‚¡ä»·èµ°åŠ¿",
                results=[],
                provider="None",
                success=False,
                error_message="å¢å¼ºæœç´¢æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
            )

    def search_stock_with_enhanced_fallback(
        self,
        stock_code: str,
        stock_name: str,
        include_news: bool = True,
        include_price: bool = False,
        max_results: int = 5
    ) -> Dict[str, SearchResponse]:
        """
        ç»¼åˆæœç´¢æ¥å£ï¼ˆæ”¯æŒæ–°é—»å’Œè‚¡ä»·ä¿¡æ¯ï¼‰
        
        å½“ include_price=True æ—¶ï¼Œä¼šåŒæ—¶æœç´¢æ–°é—»å’Œè‚¡ä»·ä¿¡æ¯ã€‚
        ä¸»è¦ç”¨äºæ•°æ®æºå®Œå…¨å¤±è´¥æ—¶çš„å…œåº•æ–¹æ¡ˆã€‚
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            include_news: æ˜¯å¦æœç´¢æ–°é—»
            include_price: æ˜¯å¦æœç´¢è‚¡ä»·/èµ°åŠ¿ä¿¡æ¯
            max_results: æ¯ç±»æœç´¢çš„æœ€å¤§ç»“æœæ•°
            
        Returns:
            {'news': SearchResponse, 'price': SearchResponse} å­—å…¸
        """
        results = {}
        
        if include_news:
            results['news'] = self.search_stock_news(
                stock_code, 
                stock_name, 
                max_results=max_results
            )
        
        if include_price:
            results['price'] = self.search_stock_price_fallback(
                stock_code,
                stock_name,
                max_attempts=3,
                max_results=max_results
            )
        
        return results

    def format_price_search_context(self, response: SearchResponse) -> str:
        """
        å°†è‚¡ä»·æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º AI åˆ†æä¸Šä¸‹æ–‡
        
        Args:
            response: æœç´¢å“åº”å¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬ï¼Œå¯ç›´æ¥ç”¨äº AI åˆ†æ
        """
        if not response.success or not response.results:
            return "ã€è‚¡ä»·èµ°åŠ¿æœç´¢ã€‘æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·ä»¥å…¶ä»–æ¸ é“æ•°æ®ä¸ºå‡†ã€‚"
        
        lines = [
            f"ã€è‚¡ä»·èµ°åŠ¿æœç´¢ç»“æœã€‘ï¼ˆæ¥æº: {response.provider}ï¼‰",
            "âš ï¸ æ³¨æ„ï¼šä»¥ä¸‹ä¿¡æ¯æ¥è‡ªç½‘ç»œæœç´¢ï¼Œä»…ä¾›å‚è€ƒï¼Œå¯èƒ½å­˜åœ¨å»¶è¿Ÿæˆ–ä¸å‡†ç¡®ã€‚",
            ""
        ]
        
        for i, result in enumerate(response.results, 1):
            date_str = f" [{result.published_date}]" if result.published_date else ""
            lines.append(f"{i}. ã€{result.source}ã€‘{result.title}{date_str}")
            lines.append(f"   {result.snippet[:200]}...")
            lines.append("")
        
        return "\n".join(lines)


# === ä¾¿æ·å‡½æ•° ===
_search_service: Optional[SearchService] = None


def get_search_service() -> SearchService:
    """è·å–æœç´¢æœåŠ¡å•ä¾‹"""
    global _search_service
    
    if _search_service is None:
        from src.config import get_config
        config = get_config()
        
        _search_service = SearchService(
            bocha_keys=config.bocha_api_keys,
            tavily_keys=config.tavily_api_keys,
            brave_keys=config.brave_api_keys,
            serpapi_keys=config.serpapi_keys,
        )
    
    return _search_service


def reset_search_service() -> None:
    """é‡ç½®æœç´¢æœåŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _search_service
    _search_service = None


if __name__ == "__main__":
    # æµ‹è¯•æœç´¢æœåŠ¡
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
    )
    
    # æ‰‹åŠ¨æµ‹è¯•ï¼ˆéœ€è¦é…ç½® API Keyï¼‰
    service = get_search_service()
    
    if service.is_available:
        print("=== æµ‹è¯•è‚¡ç¥¨æ–°é—»æœç´¢ ===")
        response = service.search_stock_news("300389", "è‰¾æ¯”æ£®")
        print(f"æœç´¢çŠ¶æ€: {'æˆåŠŸ' if response.success else 'å¤±è´¥'}")
        print(f"æœç´¢å¼•æ“: {response.provider}")
        print(f"ç»“æœæ•°é‡: {len(response.results)}")
        print(f"è€—æ—¶: {response.search_time:.2f}s")
        print("\n" + response.to_context())
    else:
        print("æœªé…ç½®æœç´¢å¼•æ“ API Keyï¼Œè·³è¿‡æµ‹è¯•")
